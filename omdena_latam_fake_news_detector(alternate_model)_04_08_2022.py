# -*- coding: utf-8 -*-
"""Omdena_LATAM_Fake_News_Detector(Alternate_Model)_04_08_2022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gqycLBVgFcUfGN9j7aErS4HnPa6DRUs3

## **Omdena LATAM Fake News Detector Model**
"""

import pandas as pd
import numpy as np
import re
import string
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

df_train = pd.read_parquet('/content/16eac85914e04a167f656392c2850aac197133366a5d953a9499702e5360d7a4')
df_test = pd.read_parquet('/content/df1dafd7a13176813587af8ca6367f723827be4a93522907e443925340f4e445')

df_train.head()

df_test.head()

#df_news = pd.read_csv("/content/fake-news_preprocessed-corrected_train.csv")

#df_news.head()

df_train = df_train[["Title", "Content", "Prediction", "Text"]]
df_test = df_test[["Title", "Content", "Prediction", "Text"]]

df_train.head()

df_test.head()

fake_df = df_test[df_test["Prediction"] == "Fake"]
true_df = df_test[df_test["Prediction"] == "True"]

fake_df.head()

true_df.head()

fake_df.info()

true_df.info()

fake_df['class'] = 1
true_df['class'] = 0

testing_csv = pd.concat([fake_df[:10], true_df[:10]], axis=0)
testing_csv.to_csv('testing.csv')

df_merged = pd.concat([fake_df, true_df], axis=0)

df_merged.sample(10).head(10)

df_merged_new = df_merged[["Content", "class"]]
df_merged_new = df_merged.sample(frac=1)

df_merged_new.head()

df_merged_new.isnull().sum()

df_merged_new.dropna()

df_merged_new.info()

df_merged_new = df_merged_new[['Content', 'class']]

df_merged_new.head()

df_merged_new

x = df_merged_new['Content'].fillna('')
y = df_merged_new['class']

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.30)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorization = TfidfVectorizer()
vector_train = vectorization.fit_transform(X_train)
vector_test = vectorization.transform(X_test)

"""### **Logistic Regression**

"""

from sklearn.linear_model import LogisticRegression

LR = LogisticRegression()
LR.fit(vector_train, y_train)

LR.score(vector_test, y_test)

pred_LR = LR.predict(vector_test)

print(classification_report(y_test, pred_LR))

"""## **Decision Tree**

"""

from sklearn.tree import DecisionTreeClassifier

DT = DecisionTreeClassifier()
DT.fit(vector_train, y_train)

DT.score(vector_test, y_test)

pred_DT = DT.predict(vector_test)

print(classification_report(y_test, pred_DT))

"""### **Gradient Boost**"""

from sklearn.ensemble import GradientBoostingClassifier

GBR = GradientBoostingClassifier()
GBR.fit(vector_train, y_train)

GBR.score(vector_test, y_test)

pred_GBR = GBR.predict(vector_test)

print(classification_report(y_test, pred_GBR))

"""### **Random Forest**"""

from sklearn.ensemble import RandomForestClassifier

RFC = RandomForestClassifier()
RFC.fit(vector_train, y_train)

RFC.score(vector_test, y_test)

pred_RFC = RFC.predict(vector_test)

print(classification_report(y_test, pred_RFC))

!pip install https://github.com/ydataai/pandas-profiling/archive/master.zip --quiet
!pip install scipy --quiet

from pandas_profiling import ProfileReport

profile = ProfileReport(df_merged_new, title='Profile Report', html={'style':{'full_width':True}})

profile.to_notebook_iframe()

!pip install explainerdashboard --quiet

from sklearn.ensemble import StackingClassifier

estimator_list = [('RF', RFC),
                  ('DT', DT),
                  ('GBR', GBR)]

stack_model = StackingClassifier(estimators = estimator_list, final_estimator=LogisticRegression()
 )

stack_model.fit(vector_train, y_train)

y_test_pred_1 = stack_model.predict(vector_test)
y_train_pred = stack_model.predict(vector_train).reshape(1, -1)
y_test_pred = stack_model.predict(vector_test).reshape(1, -1)

stack_model.score(vector_test, y_test)

print(classification_report(y_test, y_test_pred_1))

!pip install pickle4 --quiet

import pickle

pickle.dump(stack_model, open('stacked_model.pkl', 'wb'))

